{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Parameters for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "input_size = (224, 224) \n",
    "batch_size = 20 # Select max size for the GPU RAM\n",
    "val_split = 0.15 # ratio for validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup all Paths Needed for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"./dataset cv ai 2021\" # Edit this to point to your dataset location\n",
    "\n",
    "# make root directory for all training outputs\n",
    "root_dir = \"./training_outputs\"\n",
    "# Make folder for viewing augmented images \n",
    "augment_dir = \"{}/augmented_images\".format(root_dir)\n",
    "# tensorboard logs\n",
    "logs = \"{}/tensorboard_logs\".format(root_dir)\n",
    "# for saving keras models\n",
    "models_path = \"{}/models\".format(root_dir)\n",
    "\n",
    "# automatically create the folders if they dont already exist\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "os.makedirs(augment_dir, exist_ok=True)\n",
    "os.makedirs(logs, exist_ok=True)\n",
    "os.makedirs(models_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 255 images belonging to 3 classes.\n",
      "Found 45 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create datagenerator object for loading and preparing image data for training\n",
    "dataflow_kwargs = dict(\n",
    "    directory = data_root, \n",
    "    target_size = input_size, \n",
    "    class_mode = \"categorical\",\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,     \n",
    "    interpolation = \"bilinear\",\n",
    "    )\n",
    "\n",
    "# add minor augmentation to help prevent overfitting\n",
    "datagen_args_train = dict(\n",
    "    rescale = 1./255,\n",
    "    validation_split = val_split,\n",
    "    # image augmentation params\n",
    "    rotation_range = 8,\n",
    "    width_shift_range = 0.05,\n",
    "    height_shift_range = 0.1,\n",
    "    brightness_range = (0.7, 1.0),\n",
    "    shear_range = 2,\n",
    "    zoom_range = [0.8, 1.0],\n",
    "    vertical_flip = False,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = \"constant\",\n",
    "        )\n",
    "datagen_args_val = dict(\n",
    "    rescale = 1./255,\n",
    "    validation_split = val_split\n",
    "        )\n",
    "\n",
    "datagen_train = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_args_train)\n",
    "datagen_val = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_args_val)\n",
    "\n",
    "train_generator = datagen_train.flow_from_directory(\n",
    "    subset = \"training\",\n",
    "    # view augemented images\n",
    "    save_to_dir = augment_dir,\n",
    "    save_prefix = \"train\",\n",
    "    save_format = \"jpg\",\n",
    "    **dataflow_kwargs)\n",
    "\n",
    "# Dont use augmentation on the validation set\n",
    "valid_generator = datagen_val.flow_from_directory(\n",
    "    subset = \"validation\",\n",
    "    **dataflow_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create callbacks for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir = logs, \n",
    "    histogram_freq = 1,\n",
    "    write_steps_per_second = True, # Only available in tf2.5\n",
    "    update_freq = \"epoch\",\n",
    "    embeddings_freq = 0 # freq for viewing embedding layers\n",
    "    )\n",
    "# Save the model when the validation loss improves\n",
    "save_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = models_path + \"/epoch-{epoch:04d}/model.h5\", # Create new sub dir for each saved model\n",
    "    monitor = \"val_loss\",\n",
    "    verbose = 1, \n",
    "    save_best_only = True, \n",
    "    save_weights_only = False, # False: h5.pb, True: checkpoint file\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set steps so that all images are processed per epoch\n",
    "steps_per_epoch = math.ceil(train_generator.samples / train_generator.batch_size)\n",
    "validation_steps = math.ceil(valid_generator.samples / valid_generator.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create very small model to prevent overfitting\n",
    "num_classes = 3 # change later to dynamicaly get class number\n",
    "\n",
    "keras_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(input_size[0], input_size[1], 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 302,755\n",
      "Trainable params: 302,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian.Orr.ENERSERV\\Anaconda3\\envs\\TF2-6\\lib\\site-packages\\keras\\backend.py:4846: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 10s 520ms/step - loss: 1.0998 - accuracy: 0.2941 - val_loss: 1.0982 - val_accuracy: 0.2444\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.09825, saving model to ./training_outputs/models/epoch-0001\\model.h5\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 6s 456ms/step - loss: 1.0977 - accuracy: 0.3922 - val_loss: 1.0961 - val_accuracy: 0.2889\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.09825 to 1.09609, saving model to ./training_outputs/models/epoch-0002\\model.h5\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 6s 442ms/step - loss: 1.0934 - accuracy: 0.3765 - val_loss: 1.0921 - val_accuracy: 0.4444\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.09609 to 1.09212, saving model to ./training_outputs/models/epoch-0003\\model.h5\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 7s 528ms/step - loss: 1.0970 - accuracy: 0.3490 - val_loss: 1.0939 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.09212\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 7s 500ms/step - loss: 1.0828 - accuracy: 0.4157 - val_loss: 1.0931 - val_accuracy: 0.3778\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.09212\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 6s 479ms/step - loss: 1.0720 - accuracy: 0.4824 - val_loss: 1.1172 - val_accuracy: 0.3111\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.09212\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 7s 524ms/step - loss: 1.0861 - accuracy: 0.3922 - val_loss: 1.1786 - val_accuracy: 0.3111\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.09212\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 6s 481ms/step - loss: 1.0840 - accuracy: 0.4196 - val_loss: 1.0956 - val_accuracy: 0.3556\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.09212\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 6s 500ms/step - loss: 1.0751 - accuracy: 0.4745 - val_loss: 1.0971 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.09212\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 7s 510ms/step - loss: 1.0662 - accuracy: 0.4510 - val_loss: 1.1347 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.09212\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 6s 499ms/step - loss: 1.0251 - accuracy: 0.4667 - val_loss: 1.1108 - val_accuracy: 0.3778\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.09212\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 7s 531ms/step - loss: 1.0488 - accuracy: 0.4314 - val_loss: 1.1274 - val_accuracy: 0.4444\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.09212\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 7s 514ms/step - loss: 1.0246 - accuracy: 0.4667 - val_loss: 1.1294 - val_accuracy: 0.3778\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.09212\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 7s 551ms/step - loss: 1.0097 - accuracy: 0.4824 - val_loss: 1.1730 - val_accuracy: 0.3556\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.09212\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 7s 508ms/step - loss: 0.9915 - accuracy: 0.5412 - val_loss: 1.0656 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.09212 to 1.06561, saving model to ./training_outputs/models/epoch-0015\\model.h5\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 7s 559ms/step - loss: 0.9710 - accuracy: 0.5608 - val_loss: 1.1591 - val_accuracy: 0.4444\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.06561\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 7s 505ms/step - loss: 1.0021 - accuracy: 0.5059 - val_loss: 1.0878 - val_accuracy: 0.3556\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.06561\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 7s 511ms/step - loss: 0.9531 - accuracy: 0.6000 - val_loss: 1.0584 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.06561 to 1.05837, saving model to ./training_outputs/models/epoch-0018\\model.h5\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 7s 520ms/step - loss: 0.9251 - accuracy: 0.5451 - val_loss: 1.0511 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.05837 to 1.05112, saving model to ./training_outputs/models/epoch-0019\\model.h5\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 7s 530ms/step - loss: 0.9316 - accuracy: 0.6235 - val_loss: 1.0798 - val_accuracy: 0.4222\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.05112\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 7s 508ms/step - loss: 0.9011 - accuracy: 0.6510 - val_loss: 1.1582 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.05112\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 7s 527ms/step - loss: 0.9200 - accuracy: 0.6157 - val_loss: 1.2043 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.05112\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 7s 552ms/step - loss: 0.9061 - accuracy: 0.6118 - val_loss: 0.9983 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.05112 to 0.99830, saving model to ./training_outputs/models/epoch-0023\\model.h5\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 8s 619ms/step - loss: 0.8818 - accuracy: 0.6314 - val_loss: 1.1135 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.99830\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 7s 522ms/step - loss: 0.9054 - accuracy: 0.5961 - val_loss: 1.0831 - val_accuracy: 0.4444\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.99830\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 7s 526ms/step - loss: 0.8778 - accuracy: 0.6549 - val_loss: 1.0913 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.99830\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 7s 555ms/step - loss: 0.9240 - accuracy: 0.6392 - val_loss: 1.0852 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.99830\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 7s 533ms/step - loss: 0.9087 - accuracy: 0.6118 - val_loss: 1.1176 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.99830\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 7s 508ms/step - loss: 0.8390 - accuracy: 0.6627 - val_loss: 1.0998 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.99830\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 7s 554ms/step - loss: 0.8436 - accuracy: 0.6667 - val_loss: 1.0664 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.99830\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 7s 549ms/step - loss: 0.8351 - accuracy: 0.6667 - val_loss: 1.0355 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.99830\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 7s 511ms/step - loss: 0.8183 - accuracy: 0.6745 - val_loss: 1.1102 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.99830\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 7s 516ms/step - loss: 0.7792 - accuracy: 0.6941 - val_loss: 1.2387 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.99830\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 8s 586ms/step - loss: 0.7790 - accuracy: 0.7137 - val_loss: 1.1867 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.99830\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 7s 532ms/step - loss: 0.7317 - accuracy: 0.7373 - val_loss: 1.2476 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.99830\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 7s 513ms/step - loss: 0.7491 - accuracy: 0.7255 - val_loss: 1.1664 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.99830\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 7s 490ms/step - loss: 0.7657 - accuracy: 0.6902 - val_loss: 1.1367 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.99830\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 7s 503ms/step - loss: 0.7404 - accuracy: 0.7647 - val_loss: 1.1917 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.99830\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 7s 511ms/step - loss: 0.7275 - accuracy: 0.7373 - val_loss: 1.3217 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.99830\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 7s 535ms/step - loss: 0.7321 - accuracy: 0.7725 - val_loss: 1.1527 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.99830\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 7s 572ms/step - loss: 0.7380 - accuracy: 0.7529 - val_loss: 1.2410 - val_accuracy: 0.4222\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.99830\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 7s 520ms/step - loss: 0.6942 - accuracy: 0.7569 - val_loss: 1.1321 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.99830\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 7s 543ms/step - loss: 0.7170 - accuracy: 0.7569 - val_loss: 1.1191 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.99830\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 7s 500ms/step - loss: 0.6746 - accuracy: 0.7608 - val_loss: 1.2236 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.99830\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 6s 486ms/step - loss: 0.7786 - accuracy: 0.6980 - val_loss: 1.0765 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.99830\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 6s 483ms/step - loss: 0.8401 - accuracy: 0.6510 - val_loss: 1.3203 - val_accuracy: 0.4444\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.99830\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 7s 538ms/step - loss: 0.7431 - accuracy: 0.7294 - val_loss: 1.2110 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.99830\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.7221 - accuracy: 0.7412 - val_loss: 1.1110 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.99830\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 6s 469ms/step - loss: 0.6447 - accuracy: 0.7961 - val_loss: 1.2717 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.99830\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 7s 529ms/step - loss: 0.6691 - accuracy: 0.8118 - val_loss: 1.4770 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.99830\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 7s 525ms/step - loss: 0.6678 - accuracy: 0.7882 - val_loss: 1.2651 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.99830\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 8s 648ms/step - loss: 0.6446 - accuracy: 0.8196 - val_loss: 1.2155 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.99830\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 7s 572ms/step - loss: 0.6293 - accuracy: 0.8039 - val_loss: 1.2297 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.99830\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 8s 579ms/step - loss: 0.6520 - accuracy: 0.7961 - val_loss: 1.1666 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.99830\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 7s 524ms/step - loss: 0.5910 - accuracy: 0.8078 - val_loss: 1.3030 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.99830\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 7s 515ms/step - loss: 0.6434 - accuracy: 0.7922 - val_loss: 1.3070 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.99830\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 7s 529ms/step - loss: 0.6247 - accuracy: 0.8157 - val_loss: 1.1998 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.99830\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 6s 479ms/step - loss: 0.6482 - accuracy: 0.8078 - val_loss: 1.1178 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.99830\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 7s 539ms/step - loss: 0.6362 - accuracy: 0.8196 - val_loss: 1.0869 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.99830\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 0.5883 - accuracy: 0.8471 - val_loss: 1.2737 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.99830\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 7s 554ms/step - loss: 0.5714 - accuracy: 0.8392 - val_loss: 1.1790 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.99830\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 7s 503ms/step - loss: 0.5506 - accuracy: 0.8510 - val_loss: 1.4172 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.99830\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 6s 500ms/step - loss: 0.5539 - accuracy: 0.8667 - val_loss: 1.3399 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.99830\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 7s 511ms/step - loss: 0.5706 - accuracy: 0.8431 - val_loss: 1.1978 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.99830\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.5345 - accuracy: 0.8784 - val_loss: 1.2342 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.99830\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 7s 511ms/step - loss: 0.5649 - accuracy: 0.8706 - val_loss: 1.2236 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.99830\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 7s 513ms/step - loss: 0.5520 - accuracy: 0.8588 - val_loss: 1.2513 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.99830\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 6s 482ms/step - loss: 0.5289 - accuracy: 0.8784 - val_loss: 1.2293 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.99830\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 7s 518ms/step - loss: 0.4923 - accuracy: 0.9137 - val_loss: 1.3916 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.99830\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 7s 499ms/step - loss: 0.4835 - accuracy: 0.9176 - val_loss: 1.4491 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.99830\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 7s 519ms/step - loss: 0.5359 - accuracy: 0.8824 - val_loss: 1.3248 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.99830\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 7s 535ms/step - loss: 0.5274 - accuracy: 0.8824 - val_loss: 1.2795 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.99830\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 7s 510ms/step - loss: 0.4989 - accuracy: 0.8863 - val_loss: 1.2413 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.99830\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 7s 503ms/step - loss: 0.4919 - accuracy: 0.9176 - val_loss: 1.3467 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.99830\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 7s 530ms/step - loss: 0.5473 - accuracy: 0.8902 - val_loss: 1.3041 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.99830\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 7s 536ms/step - loss: 0.5327 - accuracy: 0.8667 - val_loss: 1.4947 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.99830\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 7s 520ms/step - loss: 0.5227 - accuracy: 0.8902 - val_loss: 1.3628 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.99830\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 7s 506ms/step - loss: 0.4942 - accuracy: 0.9137 - val_loss: 1.5093 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.99830\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 6s 478ms/step - loss: 0.4879 - accuracy: 0.9098 - val_loss: 1.3927 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.99830\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.4768 - accuracy: 0.9373 - val_loss: 1.3386 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.99830\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 6s 464ms/step - loss: 0.4945 - accuracy: 0.8941 - val_loss: 1.4667 - val_accuracy: 0.4222\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.99830\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 0.5266 - accuracy: 0.8941 - val_loss: 1.3180 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.99830\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 6s 483ms/step - loss: 0.4782 - accuracy: 0.9294 - val_loss: 1.4602 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.99830\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 7s 529ms/step - loss: 0.4964 - accuracy: 0.9098 - val_loss: 1.5908 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.99830\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 7s 555ms/step - loss: 0.4840 - accuracy: 0.9059 - val_loss: 1.4715 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.99830\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 7s 570ms/step - loss: 0.4680 - accuracy: 0.9255 - val_loss: 1.4963 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.99830\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 7s 514ms/step - loss: 0.4681 - accuracy: 0.9255 - val_loss: 1.3129 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.99830\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 7s 516ms/step - loss: 0.4520 - accuracy: 0.9333 - val_loss: 1.3261 - val_accuracy: 0.6444\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.99830\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 7s 513ms/step - loss: 0.4635 - accuracy: 0.9176 - val_loss: 1.4110 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.99830\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 8s 623ms/step - loss: 0.4667 - accuracy: 0.9333 - val_loss: 1.5155 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.99830\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 8s 585ms/step - loss: 0.4708 - accuracy: 0.9255 - val_loss: 1.4023 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.99830\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 7s 509ms/step - loss: 0.4597 - accuracy: 0.9255 - val_loss: 1.2978 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.99830\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 7s 516ms/step - loss: 0.4468 - accuracy: 0.9333 - val_loss: 1.4247 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.99830\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 8s 655ms/step - loss: 0.4656 - accuracy: 0.9255 - val_loss: 1.4582 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.99830\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 7s 528ms/step - loss: 0.4397 - accuracy: 0.9412 - val_loss: 1.3416 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.99830\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 9s 663ms/step - loss: 0.4367 - accuracy: 0.9333 - val_loss: 1.4218 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.99830\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 7s 550ms/step - loss: 0.4338 - accuracy: 0.9373 - val_loss: 1.2789 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.99830\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 8s 652ms/step - loss: 0.4074 - accuracy: 0.9412 - val_loss: 1.4120 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.99830\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 8s 605ms/step - loss: 0.4173 - accuracy: 0.9608 - val_loss: 1.2814 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.99830\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 0.4560 - accuracy: 0.9255 - val_loss: 1.3268 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.99830\n"
     ]
    }
   ],
   "source": [
    "history = keras_model.fit(\n",
    "    train_generator,\n",
    "    epochs = epochs, \n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    validation_data = valid_generator,\n",
    "    validation_steps = validation_steps,\n",
    "    callbacks = [tensorboard_callback, \n",
    "                save_callback]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and test the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: ./training_outputs/models/epoch-0026/model.h5\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CHRIST~1.ENE\\AppData\\Local\\Temp/ipykernel_69468/3179113180.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{}/epoch-{}/model.h5\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mloaded_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Evaluating model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mreeval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreeval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TF2-6\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m   raise IOError(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TF2-6\\lib\\site-packages\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, compile, options)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m   \u001b[0mmeta_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TF2-6\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    116\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     raise IOError(\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: ./training_outputs/models/epoch-0026/model.h5\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "model_epoch = \"0026\" # Select the epoch to run testing on\n",
    "\n",
    "path = \"{}/epoch-{}/model.h5\".format(models_path, model_epoch)\n",
    "loaded_model = tf.keras.models.load_model(path)\n",
    "print(\"Evaluating model\")\n",
    "reeval_loss, reeval_acc = loaded_model.evaluate(valid_generator, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "354f7730fd22ff327d7c68b97f75698907879ac6047eb472e21ea4cdad7d23a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('TF2-6': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
